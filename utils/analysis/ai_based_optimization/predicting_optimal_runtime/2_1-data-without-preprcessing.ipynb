{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read dataset and make ydata-profiling dashboard\n",
    "\n",
    "#from ydata_profiling import ProfileReport\n",
    "\n",
    "df = pd.read_csv(\"../data/datasetRuntimeData.csv\")\n",
    "#Drop index col\n",
    "df = df.drop([\"Unnamed: 0\"], axis=1)\n",
    "#Remove special symbole\n",
    "df['AutoML_adapter'] = df['AutoML_adapter'].str.replace(':', '')\n",
    "#Apply one hot encoding\n",
    "df = pd.get_dummies(df, columns=['AutoML_adapter'], prefix='', prefix_sep='')\n",
    "\n",
    "#profile = ProfileReport(df, title=\"Profiling Report\")\n",
    "#profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data all AutoML together\n",
    "\n",
    "X = df.drop([\"runtime_limit\"], axis=1)\n",
    "y = df[\"runtime_limit\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Create prediction plot\n",
    "# def create_prediction_plot(y_test, predictions):\n",
    "#     prediction_results = pd.DataFrame({\n",
    "#         'runtime_limit_is': y_test,\n",
    "#         'runtime_limit_predicted': predictions\n",
    "#     })\n",
    "\n",
    "#     best_case_x = [0, 5, 10, 20, 40, 80, 160, 320, 640]\n",
    "#     best_case_y = [0, 5, 10, 20, 40, 80, 160, 320, 640]\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     sns.scatterplot(\n",
    "#         x='runtime_limit_predicted', \n",
    "#         y='runtime_limit_is', \n",
    "#         data=prediction_results, \n",
    "#         color='gray', marker='o'  # Using a distinct color palette\n",
    "#     )\n",
    "\n",
    "#     plt.plot(best_case_x, best_case_y)\n",
    "#     plt.xscale('log', base=10)  # Logarithmic scale for x-axis\n",
    "#     plt.yscale('log', base=10)  # Logarithmic scale for y-axis\n",
    "\n",
    "\n",
    "#     # Find the limits in log space\n",
    "#     x_min, x_max = 1, 100\n",
    "#     y_min, y_max = 1, np.exp(6.6)\n",
    "\n",
    "#     # Determine the limits to make them symmetrical in log space\n",
    "#     log_min = min(np.log10(x_min), np.log10(y_min))\n",
    "#     log_max = max(np.log10(x_max), np.log10(y_max))\n",
    "\n",
    "#     # Apply the symmetrical limits\n",
    "#     plt.xlim([10**log_min, 10**log_max])\n",
    "#     plt.ylim([10**log_min, 10**log_max])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     plt.xlabel('Optimal runtime predicted')\n",
    "#     plt.ylabel('Optimal runtime measured')\n",
    "#     #plt.legend(title='AutoML Solution', bbox_to_anchor=(1.05, 0.5), loc='center left')\n",
    "#     #plt.title('Actual vs Predicted Runtime Limits')\n",
    "#     plt.grid(True)\n",
    "#     #plt.legend(title='Series')\n",
    "#     plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,):\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Compute MAE\n",
    "    mae = MAE(predictions, y_test)\n",
    "\n",
    "    print(f\"{type(model)} Mean Absolute Error (MAE):\", round(mae))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_lgbm_model(model,):\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "\n",
    "\n",
    "    # Define parameters for the LightGBM model\n",
    "    params = {\n",
    "        'objective': 'regression',  # Set the objective as regression\n",
    "        'metric': 'mae',            # Use mean absolute error as the evaluation metric\n",
    "        'verbose': 1                # Disable verbose output\n",
    "    }\n",
    "\n",
    "    # Train the LightGBM model\n",
    "    num_round = 100\n",
    "    model = lgb.train(params, train_data, num_round, valid_sets=[test_data])\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    predictions = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    \n",
    "    # Compute MAE\n",
    "    mae = MAE(predictions, y_test)\n",
    "\n",
    "    print(f\"{type(model)} Mean Absolute Error (MAE):\", round(mae))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.dummy.DummyRegressor'> Mean Absolute Error (MAE): 104\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 193\n",
      "[LightGBM] [Info] Number of data points in the train set: 256, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 105.683594\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "<class 'lightgbm.basic.Booster'> Mean Absolute Error (MAE): 112\n",
      "<class 'sklearn.linear_model._base.LinearRegression'> Mean Absolute Error (MAE): 105\n",
      "<class 'sklearn.tree._classes.DecisionTreeRegressor'> Mean Absolute Error (MAE): 106\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPRegressor'> Mean Absolute Error (MAE): 3087\n",
      "<class 'sklearn.linear_model._ridge.Ridge'> Mean Absolute Error (MAE): 106\n",
      "<class 'sklearn.linear_model._coordinate_descent.Lasso'> Mean Absolute Error (MAE): 106\n",
      "<class 'sklearn.linear_model._coordinate_descent.ElasticNet'> Mean Absolute Error (MAE): 121\n",
      "<class 'sklearn.ensemble._forest.RandomForestRegressor'> Mean Absolute Error (MAE): 109\n",
      "<class 'sklearn.linear_model._bayes.BayesianRidge'> Mean Absolute Error (MAE): 128\n",
      "<class 'sklearn.svm._classes.SVR'> Mean Absolute Error (MAE): 104\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "models = { \"Baseline\": DummyRegressor(strategy=\"median\"), \n",
    "          \"LightGBM\": None, \n",
    "          \"Linear Regression\": LinearRegression(), \n",
    "          \"Decision Tree\": DecisionTreeRegressor(random_state=42), \n",
    "          \"Sklearn Neural Network\": MLPRegressor(random_state=42), \n",
    "          \"Ridge\": Ridge(), \n",
    "          \"Lasso\": Lasso(), \n",
    "          \"Elastic\": ElasticNet(), \n",
    "          \"Random Forest\": RandomForestRegressor(), \n",
    "          \"Bayesian\": BayesianRidge(), \n",
    "          \"SVM\": SVR()}\n",
    "\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    if model_name == \"LightGBM\":\n",
    "        models[model_name] = train_lgbm_model(model)\n",
    "    else:\n",
    "        models[model_name] = train_model(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
