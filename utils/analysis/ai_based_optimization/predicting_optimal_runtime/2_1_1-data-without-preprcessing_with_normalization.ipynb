{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Convolution1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read dataset and make ydata-profiling dashboard\n",
    "\n",
    "#from ydata_profiling import ProfileReport\n",
    "\n",
    "df = pd.read_csv(\"../data/datasetRuntimeData.csv\")\n",
    "#Drop index col\n",
    "df = df.drop([\"Unnamed: 0\"], axis=1)\n",
    "#Remove special symbole\n",
    "df['AutoML_adapter'] = df['AutoML_adapter'].str.replace(':', '')\n",
    "#Apply one hot encoding\n",
    "df = pd.get_dummies(df, columns=['AutoML_adapter'], prefix='', prefix_sep='')\n",
    "\n",
    "#profile = ProfileReport(df, title=\"Profiling Report\")\n",
    "#profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_size_in_mb</th>\n",
       "      <th>dataset_rows</th>\n",
       "      <th>dataset_cols</th>\n",
       "      <th>missing_values</th>\n",
       "      <th>duplicated_rows</th>\n",
       "      <th>duplicated_cols</th>\n",
       "      <th>outliers</th>\n",
       "      <th>runtime_limit</th>\n",
       "      <th>autogluon</th>\n",
       "      <th>evalml</th>\n",
       "      <th>flaml</th>\n",
       "      <th>gama</th>\n",
       "      <th>h2o_automl</th>\n",
       "      <th>lama</th>\n",
       "      <th>pycaret</th>\n",
       "      <th>tpot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.085659</td>\n",
       "      <td>539383</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>154622</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.085659</td>\n",
       "      <td>539383</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>154622</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.085659</td>\n",
       "      <td>539383</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>154622</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>640</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.085659</td>\n",
       "      <td>539383</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>154622</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.085659</td>\n",
       "      <td>539383</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>154622</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>0.197092</td>\n",
       "      <td>683</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>0.197092</td>\n",
       "      <td>683</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>0.197092</td>\n",
       "      <td>683</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0.197092</td>\n",
       "      <td>683</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.197092</td>\n",
       "      <td>683</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset_size_in_mb  dataset_rows  dataset_cols  missing_values  \\\n",
       "0             18.085659        539383             8               0   \n",
       "1             18.085659        539383             8               0   \n",
       "2             18.085659        539383             8               0   \n",
       "3             18.085659        539383             8               0   \n",
       "4             18.085659        539383             8               0   \n",
       "..                  ...           ...           ...             ...   \n",
       "315            0.197092           683            36               0   \n",
       "316            0.197092           683            36               0   \n",
       "317            0.197092           683            36               0   \n",
       "318            0.197092           683            36               0   \n",
       "319            0.197092           683            36               0   \n",
       "\n",
       "     duplicated_rows  duplicated_cols  outliers  runtime_limit  autogluon  \\\n",
       "0             154622                0        99             40      False   \n",
       "1             154622                0        99              5      False   \n",
       "2             154622                0        99            640      False   \n",
       "3             154622                0        99             10       True   \n",
       "4             154622                0        99             20      False   \n",
       "..               ...              ...       ...            ...        ...   \n",
       "315               41                0         0             20      False   \n",
       "316               41                0         0              5       True   \n",
       "317               41                0         0              5      False   \n",
       "318               41                0         0             20      False   \n",
       "319               41                0         0            320      False   \n",
       "\n",
       "     evalml  flaml   gama  h2o_automl   lama  pycaret   tpot  \n",
       "0     False  False  False        True  False    False  False  \n",
       "1      True  False  False       False  False    False  False  \n",
       "2     False  False   True       False  False    False  False  \n",
       "3     False  False  False       False  False    False  False  \n",
       "4     False  False  False       False   True    False  False  \n",
       "..      ...    ...    ...         ...    ...      ...    ...  \n",
       "315   False  False  False        True  False    False  False  \n",
       "316   False  False  False       False  False    False  False  \n",
       "317   False  False  False       False  False    False   True  \n",
       "318   False   True  False       False  False    False  False  \n",
       "319   False  False  False       False  False     True  False  \n",
       "\n",
       "[320 rows x 16 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data all AutoML together\n",
    "\n",
    "X = df.drop([\"runtime_limit\"], axis=1)\n",
    "y = df[\"runtime_limit\"]\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "x_scaler = MinMaxScaler()\n",
    "y_scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(x_scaler.fit_transform(X), columns=X.columns)\n",
    "y = pd.Series(y_scaler.fit_transform(y.values.reshape(-1, 1)).flatten())\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Create prediction plot\n",
    "# def create_prediction_plot(y_test, predictions):\n",
    "#     prediction_results = pd.DataFrame({\n",
    "#         'runtime_limit_is': y_test,\n",
    "#         'runtime_limit_predicted': predictions\n",
    "#     })\n",
    "\n",
    "#     best_case_x = [0, 5, 10, 20, 40, 80, 160, 320, 640]\n",
    "#     best_case_y = [0, 5, 10, 20, 40, 80, 160, 320, 640]\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     sns.scatterplot(\n",
    "#         x='runtime_limit_predicted', \n",
    "#         y='runtime_limit_is', \n",
    "#         data=prediction_results, \n",
    "#         color='gray', marker='o'  # Using a distinct color palette\n",
    "#     )\n",
    "\n",
    "#     plt.plot(best_case_x, best_case_y)\n",
    "#     plt.xscale('log', base=10)  # Logarithmic scale for x-axis\n",
    "#     plt.yscale('log', base=10)  # Logarithmic scale for y-axis\n",
    "\n",
    "\n",
    "#     # Find the limits in log space\n",
    "#     x_min, x_max = 1, 100\n",
    "#     y_min, y_max = 1, np.exp(6.6)\n",
    "\n",
    "#     # Determine the limits to make them symmetrical in log space\n",
    "#     log_min = min(np.log10(x_min), np.log10(y_min))\n",
    "#     log_max = max(np.log10(x_max), np.log10(y_max))\n",
    "\n",
    "#     # Apply the symmetrical limits\n",
    "#     plt.xlim([10**log_min, 10**log_max])\n",
    "#     plt.ylim([10**log_min, 10**log_max])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     plt.xlabel('Optimal runtime predicted')\n",
    "#     plt.ylabel('Optimal runtime measured')\n",
    "#     #plt.legend(title='AutoML Solution', bbox_to_anchor=(1.05, 0.5), loc='center left')\n",
    "#     #plt.title('Actual vs Predicted Runtime Limits')\n",
    "#     plt.grid(True)\n",
    "#     #plt.legend(title='Series')\n",
    "#     plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_model(model, n_splits=10):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    mae_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        y_test_ = pd.Series(y_scaler.inverse_transform(y_test.values.reshape(-1, 1)).flatten())\n",
    "        predictions = pd.Series(y_scaler.inverse_transform(predictions.reshape(-1, 1)).flatten())\n",
    "        \n",
    "        # Compute MAE\n",
    "        mae = MAE(predictions, y_test_)\n",
    "        mae_scores.append(mae)\n",
    "        \n",
    "    avg_mae = np.mean(mae_scores)\n",
    "    std_mae = np.std(mae_scores)  # Compute standard deviation\n",
    "    \n",
    "    print(\"###############################################\")\n",
    "    print(\"MAE Scores:\", mae_scores)\n",
    "    print(f\"{type(model)} Average MAE across {n_splits} folds: {round(avg_mae, 4)} ± {round(std_mae, 4)}\")\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model(model,):\n",
    "#     model.fit(X_train, y_train)\n",
    "#     predictions = model.predict(X_test)\n",
    "    \n",
    "#     y_test_ = pd.Series(y_scaler.inverse_transform(y_test.values.reshape(-1, 1)).flatten())\n",
    "#     predictions = pd.Series(y_scaler.inverse_transform(predictions.reshape(-1, 1)).flatten())\n",
    "\n",
    "#     # Compute MAE\n",
    "#     mae = MAE(predictions, y_test_)\n",
    "\n",
    "#     print(f\"{type(model)} Mean Absolute Error (MAE):\", round(mae))\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_keras(n_splits=10):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    mae_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Define the model\n",
    "        model = Sequential([\n",
    "            Dense(len(X_train.columns), activation='relu', input_shape=(len(X_train.columns),)),\n",
    "            Dense(1, activation='linear')\n",
    "        ])\n",
    "        \n",
    "        # Define ModelCheckpoint callback\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            './keras_models/2_1_1_best_model.keras', \n",
    "            monitor='val_mae',  # Monitor validation loss\n",
    "            save_best_only=True,  # Save only when validation loss improves\n",
    "            mode='auto'\n",
    "        )\n",
    "        \n",
    "        early_stopping_callback = EarlyStopping(\n",
    "            monitor='val_mae',  # Monitor validation MAE\n",
    "            patience=25,  # Stop training if the validation MAE doesn't improve for 10 epochs\n",
    "            restore_best_weights=True  # Restore the model weights from the best epoch\n",
    "        )\n",
    "        \n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam', loss=tf.keras.losses.MeanAbsoluteError(), metrics=['mae'])\n",
    "        model.fit(X_train, y_train, epochs=500, batch_size=16, verbose=0, callbacks=[checkpoint_callback, early_stopping_callback], validation_data=(X_test, y_test))\n",
    "        \n",
    "        model = tf.keras.models.load_model('./keras_models/2_1_1_best_model.keras')\n",
    "        predictions = pd.Series(model.predict(X_test).flatten())\n",
    "        \n",
    "        y_test_ = pd.Series(y_scaler.inverse_transform(y_test.values.reshape(-1, 1)).flatten())\n",
    "        predictions = pd.Series(y_scaler.inverse_transform(predictions.values.reshape(-1, 1)).flatten())\n",
    "        \n",
    "        # Compute MAE\n",
    "        mae = MAE(predictions, y_test_)\n",
    "        mae_scores.append(mae)\n",
    "    \n",
    "    avg_mae = np.mean(mae_scores)\n",
    "    std_mae = np.std(mae_scores)  # Compute standard deviation\n",
    "    \n",
    "    print(\"###############################################\")\n",
    "    print(\"MAE Scores:\", mae_scores)\n",
    "    print(f\"{type(model)} Average MAE across {n_splits} folds: {round(avg_mae, 4)} ± {round(std_mae, 4)}\")\n",
    "    \n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_keras():\n",
    "\n",
    "#     # Define the model\n",
    "#     model = Sequential([\n",
    "#         Dense(len(X_train.columns), activation='relu', input_shape=(len(X_train.columns),)),  # Input layer (10 features)\n",
    "#         #Dense(12, activation='relu'),  # Hidden layer 1\n",
    "#         #Dense(6, activation='relu'),  # Hidden layer 2\n",
    "#         Dense(1, activation='linear')  # Output layer (for binary classification)\n",
    "#     ])\n",
    "\n",
    "#     # Define ModelCheckpoint callback\n",
    "#     checkpoint_callback = ModelCheckpoint(\n",
    "#         './keras_models/2_1_1_best_model.h5', \n",
    "#         monitor='val_mae',  # Monitor validation loss\n",
    "#         save_best_only=True,  # Save only when validation loss improves\n",
    "#         mode='auto',  # We want to minimize validation loss\n",
    "#         #verbose=1\n",
    "#     )\n",
    "\n",
    "#     # Compile the model\n",
    "#     model.compile(optimizer='adam', loss=tf.keras.losses.MeanAbsoluteError(), metrics=['mae'])\n",
    "#     model.fit(X_train, y_train, epochs=500, batch_size=16, verbose=0, callbacks=[checkpoint_callback], validation_data=(X_test, y_test))\n",
    "    \n",
    "#     model = tf.keras.models.load_model('./keras_models/2_1_1_best_model.h5')\n",
    "#     predictions = pd.Series(model.predict(X_test).flatten())\n",
    "\n",
    "\n",
    "#     y_test_ = pd.Series(y_scaler.inverse_transform(y_test.values.reshape(-1, 1)).flatten())\n",
    "#     predictions = pd.Series(y_scaler.inverse_transform(predictions.values.reshape(-1, 1)).flatten())\n",
    "\n",
    "\n",
    "#     # Compute MAE\n",
    "#     mae = MAE(predictions, y_test_)\n",
    "\n",
    "#     print(f\"{type(model)} Mean Absolute Error (MAE):\", round(mae))\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgbm_model(n_splits=10):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    mae_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "        \n",
    "        params = {\n",
    "            'objective': 'regression',\n",
    "            'metric': 'mae',\n",
    "            'verbose': -1\n",
    "        }\n",
    "        \n",
    "        num_round = 100\n",
    "        model = lgb.train(params, train_data, num_round, valid_sets=[test_data])\n",
    "        \n",
    "        predictions = pd.Series(model.predict(X_test, num_iteration=model.best_iteration))\n",
    "        \n",
    "        y_test_ = pd.Series(y_scaler.inverse_transform(y_test.values.reshape(-1, 1)).flatten())\n",
    "        predictions = pd.Series(y_scaler.inverse_transform(predictions.values.reshape(-1, 1)).flatten())\n",
    "        \n",
    "        mae = MAE(predictions, y_test_)\n",
    "        mae_scores.append(mae)\n",
    "    \n",
    "    avg_mae = np.mean(mae_scores)\n",
    "    std_mae = np.std(mae_scores)  # Compute standard deviation\n",
    "    \n",
    "    print(\"###############################################\")\n",
    "    print(\"MAE Scores:\", mae_scores)\n",
    "    print(f\"{type(model)} Average MAE across {n_splits} folds: {round(avg_mae, 4)} ± {round(std_mae, 4)}\")\n",
    "    \n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def train_lgbm_model():\n",
    "#     train_data = lgb.Dataset(X_train, label=y_train)\n",
    "#     test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "\n",
    "\n",
    "#     # Define parameters for the LightGBM model\n",
    "#     params = {\n",
    "#         'objective': 'regression',  # Set the objective as regression\n",
    "#         'metric': 'mae',            # Use mean absolute error as the evaluation metric\n",
    "#         'verbose': 1                # Disable verbose output\n",
    "#     }\n",
    "\n",
    "#     # Train the LightGBM model\n",
    "#     num_round = 100\n",
    "#     model = lgb.train(params, train_data, num_round, valid_sets=[test_data])\n",
    "\n",
    "#     # Make predictions on the test set\n",
    "#     predictions = pd.Series(model.predict(X_test, num_iteration=model.best_iteration))\n",
    "    \n",
    "\n",
    "#     y_test_ = pd.Series(y_scaler.inverse_transform(y_test.values.reshape(-1, 1)).flatten())\n",
    "#     predictions = pd.Series(y_scaler.inverse_transform(predictions.values.reshape(-1, 1)).flatten())\n",
    "\n",
    "#     # Compute MAE\n",
    "#     mae = MAE(predictions, y_test)\n",
    "\n",
    "#     print(f\"{type(model)} Mean Absolute Error (MAE):\", round(mae))\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############################################\n",
      "MAE Scores: [104.375, 105.15625, 155.15625, 121.5625, 106.40625, 93.4375, 51.71875, 85.3125, 75.46875, 109.84375]\n",
      "<class 'sklearn.dummy.DummyRegressor'> Average MAE across 10 folds: 100.8438 ± 26.2209\n",
      "###############################################\n",
      "MAE Scores: [113.55323040477292, 124.84343273474835, 159.3062971691807, 154.26554574392338, 130.18922868181738, 107.90234932159957, 86.85027768744823, 104.56247642941943, 130.9793230422262, 130.9543923130465]\n",
      "<class 'lightgbm.basic.Booster'> Average MAE across 10 folds: 124.3407 ± 21.0325\n",
      "###############################################\n",
      "MAE Scores: [107.059326171875, 106.21536254882812, 150.897216796875, 152.530517578125, 111.43310546875, 108.013916015625, 92.574462890625, 106.3970947265625, 126.4208984375, 131.57181838189484]\n",
      "<class 'sklearn.linear_model._base.LinearRegression'> Average MAE across 10 folds: 119.3114 ± 19.2224\n",
      "###############################################\n",
      "MAE Scores: [136.25, 115.0, 160.0, 189.21875, 152.65625, 112.96875, 73.59375, 181.5625, 155.15625, 148.90625]\n",
      "<class 'sklearn.tree._classes.DecisionTreeRegressor'> Average MAE across 10 folds: 142.5312 ± 32.7637\n",
      "###############################################\n",
      "MAE Scores: [110.34976393067603, 102.71706080159727, 138.999404228829, 149.61416534568065, 117.85418852431786, 106.51991808258082, 89.38058517397702, 107.26858934305143, 123.56313121938435, 132.75808371545983]\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPRegressor'> Average MAE across 10 folds: 117.9025 ± 17.4563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "###############################################\n",
      "MAE Scores: [90.77830832451582, 85.03746999800205, 132.4339361190796, 138.99142545461655, 105.61806264519691, 92.79855471104383, 58.75854334235191, 76.4926639534533, 78.53938563168049, 113.01963271200657]\n",
      "<class 'keras.src.models.sequential.Sequential'> Average MAE across 10 folds: 97.2468 ± 24.0257\n",
      "###############################################\n",
      "MAE Scores: [104.00850144534182, 107.31159310731972, 153.28851155256277, 152.8193703695885, 114.4733857189099, 102.41316872398124, 92.43612812348644, 102.94385399530148, 120.37930239549138, 132.81458073198908]\n",
      "<class 'sklearn.linear_model._ridge.Ridge'> Average MAE across 10 folds: 118.2888 ± 20.3164\n",
      "###############################################\n",
      "MAE Scores: [118.50260416666667, 144.55729166666669, 182.861328125, 160.78125, 130.59895833333334, 124.61805555555556, 99.990234375, 112.53472222222223, 125.771484375, 132.48046875]\n",
      "<class 'sklearn.linear_model._coordinate_descent.Lasso'> Average MAE across 10 folds: 133.2696 ± 22.8866\n",
      "###############################################\n",
      "MAE Scores: [118.50260416666667, 144.55729166666669, 182.861328125, 160.78125, 130.59895833333334, 124.61805555555556, 99.990234375, 112.53472222222223, 125.771484375, 132.48046875]\n",
      "<class 'sklearn.linear_model._coordinate_descent.ElasticNet'> Average MAE across 10 folds: 133.2696 ± 22.8866\n",
      "###############################################\n",
      "MAE Scores: [110.103125, 116.69531250000001, 131.2078125, 162.5984375, 127.09843750000005, 103.88437500000003, 75.84687500000001, 130.63437500000003, 127.01250000000006, 121.03437500000003]\n",
      "<class 'sklearn.ensemble._forest.RandomForestRegressor'> Average MAE across 10 folds: 120.6116 ± 21.1384\n",
      "###############################################\n",
      "MAE Scores: [104.97482819192896, 114.21480812191068, 159.90929036675013, 152.54738215617957, 116.41941376304555, 101.79139317223691, 92.43799882201266, 105.12680952657516, 117.07705932330894, 129.9748631651125]\n",
      "<class 'sklearn.linear_model._bayes.BayesianRidge'> Average MAE across 10 folds: 119.4474 ± 20.8364\n",
      "###############################################\n",
      "MAE Scores: [103.76709263513987, 115.74344958611853, 158.8272470620184, 160.64507146970004, 113.89932494632487, 111.35965064883568, 83.5743623885387, 101.4727468419393, 112.80250408163559, 119.21100856534392]\n",
      "<class 'sklearn.svm._classes.SVR'> Average MAE across 10 folds: 118.1302 ± 22.8924\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = { \"Baseline\": DummyRegressor(strategy=\"median\"), \n",
    "          \"LightGBM\": None, \n",
    "          \"Linear Regression\": LinearRegression(), \n",
    "          \"Decision Tree\": DecisionTreeRegressor(random_state=42), \n",
    "          \"Sklearn Neural Network\": MLPRegressor(random_state=42), \n",
    "          \"Keras Neural Network\": None, \n",
    "          \"Ridge\": Ridge(), \n",
    "          \"Lasso\": Lasso(), \n",
    "          \"Elastic\": ElasticNet(), \n",
    "          \"Random Forest\": RandomForestRegressor(), \n",
    "          \"Bayesian\": BayesianRidge(), \n",
    "          \"SVM\": SVR()}\n",
    "\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    if model_name == \"LightGBM\":\n",
    "        models[model_name] = train_lgbm_model()\n",
    "    elif model_name == \"Keras Neural Network\":\n",
    "        models[model_name] = train_keras()\n",
    "    else:\n",
    "        models[model_name] = train_model(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
