{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Convolution1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read dataset and make ydata-profiling dashboard\n",
    "\n",
    "#from ydata_profiling import ProfileReport\n",
    "\n",
    "df = pd.read_csv(\"../data/datasetRuntimeData.csv\")\n",
    "#Drop index col\n",
    "df = df.drop([\"Unnamed: 0\"], axis=1)\n",
    "#Remove special symbole\n",
    "df['AutoML_adapter'] = df['AutoML_adapter'].str.replace(':', '')\n",
    "#Apply one hot encoding\n",
    "df = pd.get_dummies(df, columns=['AutoML_adapter'], prefix='', prefix_sep='')\n",
    "\n",
    "#profile = ProfileReport(df, title=\"Profiling Report\")\n",
    "#profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_size_in_mb</th>\n",
       "      <th>dataset_rows</th>\n",
       "      <th>dataset_cols</th>\n",
       "      <th>missing_values</th>\n",
       "      <th>duplicated_rows</th>\n",
       "      <th>duplicated_cols</th>\n",
       "      <th>outliers</th>\n",
       "      <th>runtime_limit</th>\n",
       "      <th>autogluon</th>\n",
       "      <th>evalml</th>\n",
       "      <th>flaml</th>\n",
       "      <th>gama</th>\n",
       "      <th>h2o_automl</th>\n",
       "      <th>lama</th>\n",
       "      <th>pycaret</th>\n",
       "      <th>tpot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.085659</td>\n",
       "      <td>539383</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>154622</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.085659</td>\n",
       "      <td>539383</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>154622</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.085659</td>\n",
       "      <td>539383</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>154622</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>640</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.085659</td>\n",
       "      <td>539383</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>154622</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.085659</td>\n",
       "      <td>539383</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>154622</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>0.197092</td>\n",
       "      <td>683</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>0.197092</td>\n",
       "      <td>683</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>0.197092</td>\n",
       "      <td>683</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0.197092</td>\n",
       "      <td>683</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.197092</td>\n",
       "      <td>683</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset_size_in_mb  dataset_rows  dataset_cols  missing_values  \\\n",
       "0             18.085659        539383             8               0   \n",
       "1             18.085659        539383             8               0   \n",
       "2             18.085659        539383             8               0   \n",
       "3             18.085659        539383             8               0   \n",
       "4             18.085659        539383             8               0   \n",
       "..                  ...           ...           ...             ...   \n",
       "315            0.197092           683            36               0   \n",
       "316            0.197092           683            36               0   \n",
       "317            0.197092           683            36               0   \n",
       "318            0.197092           683            36               0   \n",
       "319            0.197092           683            36               0   \n",
       "\n",
       "     duplicated_rows  duplicated_cols  outliers  runtime_limit  autogluon  \\\n",
       "0             154622                0        99             40      False   \n",
       "1             154622                0        99              5      False   \n",
       "2             154622                0        99            640      False   \n",
       "3             154622                0        99             10       True   \n",
       "4             154622                0        99             20      False   \n",
       "..               ...              ...       ...            ...        ...   \n",
       "315               41                0         0             20      False   \n",
       "316               41                0         0              5       True   \n",
       "317               41                0         0              5      False   \n",
       "318               41                0         0             20      False   \n",
       "319               41                0         0            320      False   \n",
       "\n",
       "     evalml  flaml   gama  h2o_automl   lama  pycaret   tpot  \n",
       "0     False  False  False        True  False    False  False  \n",
       "1      True  False  False       False  False    False  False  \n",
       "2     False  False   True       False  False    False  False  \n",
       "3     False  False  False       False  False    False  False  \n",
       "4     False  False  False       False   True    False  False  \n",
       "..      ...    ...    ...         ...    ...      ...    ...  \n",
       "315   False  False  False        True  False    False  False  \n",
       "316   False  False  False       False  False    False  False  \n",
       "317   False  False  False       False  False    False   True  \n",
       "318   False   True  False       False  False    False  False  \n",
       "319   False  False  False       False  False     True  False  \n",
       "\n",
       "[320 rows x 16 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data all AutoML together\n",
    "\n",
    "X = df.drop([\"runtime_limit\"], axis=1)\n",
    "y = df[\"runtime_limit\"]\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "x_scaler = MinMaxScaler()\n",
    "y_scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(x_scaler.fit_transform(X), columns=X.columns)\n",
    "y = pd.Series(y_scaler.fit_transform(y.values.reshape(-1, 1)).flatten())\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create prediction plot\n",
    "def create_prediction_plot(y_test, predictions):\n",
    "    prediction_results = pd.DataFrame({\n",
    "        'runtime_limit_is': y_test,\n",
    "        'runtime_limit_predicted': predictions\n",
    "    })\n",
    "\n",
    "    best_case_x = [0, 5, 10, 20, 40, 80, 160, 320, 640]\n",
    "    best_case_y = [0, 5, 10, 20, 40, 80, 160, 320, 640]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(\n",
    "        x='runtime_limit_predicted', \n",
    "        y='runtime_limit_is', \n",
    "        data=prediction_results, \n",
    "        color='gray', marker='o'  # Using a distinct color palette\n",
    "    )\n",
    "\n",
    "    plt.plot(best_case_x, best_case_y)\n",
    "    plt.xscale('log', base=10)  # Logarithmic scale for x-axis\n",
    "    plt.yscale('log', base=10)  # Logarithmic scale for y-axis\n",
    "\n",
    "\n",
    "    # Find the limits in log space\n",
    "    x_min, x_max = 1, 100\n",
    "    y_min, y_max = 1, np.exp(6.6)\n",
    "\n",
    "    # Determine the limits to make them symmetrical in log space\n",
    "    log_min = min(np.log10(x_min), np.log10(y_min))\n",
    "    log_max = max(np.log10(x_max), np.log10(y_max))\n",
    "\n",
    "    # Apply the symmetrical limits\n",
    "    plt.xlim([10**log_min, 10**log_max])\n",
    "    plt.ylim([10**log_min, 10**log_max])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    plt.xlabel('Optimal runtime predicted')\n",
    "    plt.ylabel('Optimal runtime measured')\n",
    "    #plt.legend(title='AutoML Solution', bbox_to_anchor=(1.05, 0.5), loc='center left')\n",
    "    #plt.title('Actual vs Predicted Runtime Limits')\n",
    "    plt.grid(True)\n",
    "    #plt.legend(title='Series')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_size_in_mb</th>\n",
       "      <th>dataset_rows</th>\n",
       "      <th>dataset_cols</th>\n",
       "      <th>missing_values</th>\n",
       "      <th>duplicated_rows</th>\n",
       "      <th>duplicated_cols</th>\n",
       "      <th>outliers</th>\n",
       "      <th>autogluon</th>\n",
       "      <th>evalml</th>\n",
       "      <th>flaml</th>\n",
       "      <th>gama</th>\n",
       "      <th>h2o_automl</th>\n",
       "      <th>lama</th>\n",
       "      <th>pycaret</th>\n",
       "      <th>tpot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.034972</td>\n",
       "      <td>0.928289</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.034972</td>\n",
       "      <td>0.928289</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.034972</td>\n",
       "      <td>0.928289</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.034972</td>\n",
       "      <td>0.928289</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.034972</td>\n",
       "      <td>0.928289</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.007454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.007454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.007454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.007454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.007454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset_size_in_mb  dataset_rows  dataset_cols  missing_values  \\\n",
       "0              0.034972      0.928289      0.000932             0.0   \n",
       "1              0.034972      0.928289      0.000932             0.0   \n",
       "2              0.034972      0.928289      0.000932             0.0   \n",
       "3              0.034972      0.928289      0.000932             0.0   \n",
       "4              0.034972      0.928289      0.000932             0.0   \n",
       "..                  ...           ...           ...             ...   \n",
       "315            0.000352      0.000315      0.007454             0.0   \n",
       "316            0.000352      0.000315      0.007454             0.0   \n",
       "317            0.000352      0.000315      0.007454             0.0   \n",
       "318            0.000352      0.000315      0.007454             0.0   \n",
       "319            0.000352      0.000315      0.007454             0.0   \n",
       "\n",
       "     duplicated_rows  duplicated_cols  outliers  autogluon  evalml  flaml  \\\n",
       "0           1.000000              0.0  0.000234        0.0     0.0    0.0   \n",
       "1           1.000000              0.0  0.000234        0.0     1.0    0.0   \n",
       "2           1.000000              0.0  0.000234        0.0     0.0    0.0   \n",
       "3           1.000000              0.0  0.000234        1.0     0.0    0.0   \n",
       "4           1.000000              0.0  0.000234        0.0     0.0    0.0   \n",
       "..               ...              ...       ...        ...     ...    ...   \n",
       "315         0.000265              0.0  0.000000        0.0     0.0    0.0   \n",
       "316         0.000265              0.0  0.000000        1.0     0.0    0.0   \n",
       "317         0.000265              0.0  0.000000        0.0     0.0    0.0   \n",
       "318         0.000265              0.0  0.000000        0.0     0.0    1.0   \n",
       "319         0.000265              0.0  0.000000        0.0     0.0    0.0   \n",
       "\n",
       "     gama  h2o_automl  lama  pycaret  tpot  \n",
       "0     0.0         1.0   0.0      0.0   0.0  \n",
       "1     0.0         0.0   0.0      0.0   0.0  \n",
       "2     1.0         0.0   0.0      0.0   0.0  \n",
       "3     0.0         0.0   0.0      0.0   0.0  \n",
       "4     0.0         0.0   1.0      0.0   0.0  \n",
       "..    ...         ...   ...      ...   ...  \n",
       "315   0.0         1.0   0.0      0.0   0.0  \n",
       "316   0.0         0.0   0.0      0.0   0.0  \n",
       "317   0.0         0.0   0.0      0.0   1.0  \n",
       "318   0.0         0.0   0.0      0.0   0.0  \n",
       "319   0.0         0.0   0.0      1.0   0.0  \n",
       "\n",
       "[320 rows x 15 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selected_feature = [\"autogluon\", \"evalml\", \"flaml\", \"gama\", \"h2o_automl\", \"lama\", \"pycaret\", \"tpot\", \"dataset_rows\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_model(model, n_splits=10):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    mae_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        model.fit(X_train[selected_feature], y_train)\n",
    "        predictions = model.predict(X_test[selected_feature])\n",
    "        \n",
    "        y_test_ = pd.Series(y_scaler.inverse_transform(y_test.values.reshape(-1, 1)).flatten())\n",
    "        predictions = pd.Series(y_scaler.inverse_transform(predictions.reshape(-1, 1)).flatten())\n",
    "        \n",
    "        # Compute MAE\n",
    "        mae = MAE(predictions, y_test_)\n",
    "        mae_scores.append(mae)\n",
    "        \n",
    "    avg_mae = np.mean(mae_scores)\n",
    "    std_mae = np.std(mae_scores)  # Compute standard deviation\n",
    "    \n",
    "    print(\"###############################################\")\n",
    "    print(\"MAE Scores:\", mae_scores)\n",
    "    print(f\"{type(model)} Average MAE across {n_splits} folds: {round(avg_mae, 4)} ± {round(std_mae, 4)}\")\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model(model,):\n",
    "#     model.fit(X_train[selected_feature], y_train)\n",
    "#     predictions = pd.Series(model.predict(X_test[selected_feature]))\n",
    "\n",
    "#     y_test_ = pd.Series(y_scaler.inverse_transform(y_test.values.reshape(-1, 1)).flatten())\n",
    "#     predictions = pd.Series(y_scaler.inverse_transform(predictions.values.reshape(-1, 1)).flatten())\n",
    "\n",
    "#     # Compute MAE\n",
    "#     mae = MAE(predictions, y_test_)\n",
    "    \n",
    "#     print(f\"{type(model)} Mean Absolute Error (MAE):\", round(mae))\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_size_in_mb</th>\n",
       "      <th>dataset_rows</th>\n",
       "      <th>dataset_cols</th>\n",
       "      <th>missing_values</th>\n",
       "      <th>duplicated_rows</th>\n",
       "      <th>duplicated_cols</th>\n",
       "      <th>outliers</th>\n",
       "      <th>autogluon</th>\n",
       "      <th>evalml</th>\n",
       "      <th>flaml</th>\n",
       "      <th>gama</th>\n",
       "      <th>h2o_automl</th>\n",
       "      <th>lama</th>\n",
       "      <th>pycaret</th>\n",
       "      <th>tpot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.034972</td>\n",
       "      <td>0.928289</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.034972</td>\n",
       "      <td>0.928289</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.034972</td>\n",
       "      <td>0.928289</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.034972</td>\n",
       "      <td>0.928289</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.034972</td>\n",
       "      <td>0.928289</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.007454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.007454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.007454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.007454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.007454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset_size_in_mb  dataset_rows  dataset_cols  missing_values  \\\n",
       "0              0.034972      0.928289      0.000932             0.0   \n",
       "1              0.034972      0.928289      0.000932             0.0   \n",
       "2              0.034972      0.928289      0.000932             0.0   \n",
       "3              0.034972      0.928289      0.000932             0.0   \n",
       "4              0.034972      0.928289      0.000932             0.0   \n",
       "..                  ...           ...           ...             ...   \n",
       "315            0.000352      0.000315      0.007454             0.0   \n",
       "316            0.000352      0.000315      0.007454             0.0   \n",
       "317            0.000352      0.000315      0.007454             0.0   \n",
       "318            0.000352      0.000315      0.007454             0.0   \n",
       "319            0.000352      0.000315      0.007454             0.0   \n",
       "\n",
       "     duplicated_rows  duplicated_cols  outliers  autogluon  evalml  flaml  \\\n",
       "0           1.000000              0.0  0.000234        0.0     0.0    0.0   \n",
       "1           1.000000              0.0  0.000234        0.0     1.0    0.0   \n",
       "2           1.000000              0.0  0.000234        0.0     0.0    0.0   \n",
       "3           1.000000              0.0  0.000234        1.0     0.0    0.0   \n",
       "4           1.000000              0.0  0.000234        0.0     0.0    0.0   \n",
       "..               ...              ...       ...        ...     ...    ...   \n",
       "315         0.000265              0.0  0.000000        0.0     0.0    0.0   \n",
       "316         0.000265              0.0  0.000000        1.0     0.0    0.0   \n",
       "317         0.000265              0.0  0.000000        0.0     0.0    0.0   \n",
       "318         0.000265              0.0  0.000000        0.0     0.0    1.0   \n",
       "319         0.000265              0.0  0.000000        0.0     0.0    0.0   \n",
       "\n",
       "     gama  h2o_automl  lama  pycaret  tpot  \n",
       "0     0.0         1.0   0.0      0.0   0.0  \n",
       "1     0.0         0.0   0.0      0.0   0.0  \n",
       "2     1.0         0.0   0.0      0.0   0.0  \n",
       "3     0.0         0.0   0.0      0.0   0.0  \n",
       "4     0.0         0.0   1.0      0.0   0.0  \n",
       "..    ...         ...   ...      ...   ...  \n",
       "315   0.0         1.0   0.0      0.0   0.0  \n",
       "316   0.0         0.0   0.0      0.0   0.0  \n",
       "317   0.0         0.0   0.0      0.0   1.0  \n",
       "318   0.0         0.0   0.0      0.0   0.0  \n",
       "319   0.0         0.0   0.0      1.0   0.0  \n",
       "\n",
       "[320 rows x 15 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_keras(n_splits=10):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    mae_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Define the model\n",
    "        model = Sequential([\n",
    "            Dense(len(X_train[selected_feature].columns), activation='relu', input_shape=(len(X_train[selected_feature].columns),)),\n",
    "            Dense(1, activation='linear')\n",
    "        ])\n",
    "        \n",
    "        # Define ModelCheckpoint callback\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            './keras_models/2_3_1_best_model.keras', \n",
    "            monitor='val_mae',  # Monitor validation loss\n",
    "            save_best_only=True,  # Save only when validation loss improves\n",
    "            mode='auto'\n",
    "        )\n",
    "        \n",
    "        early_stopping_callback = EarlyStopping(\n",
    "            monitor='val_mae',  # Monitor validation MAE\n",
    "            patience=25,  # Stop training if the validation MAE doesn't improve for 10 epochs\n",
    "            restore_best_weights=True  # Restore the model weights from the best epoch\n",
    "        )\n",
    "        \n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam', loss=tf.keras.losses.MeanAbsoluteError(), metrics=['mae'])\n",
    "        model.fit(X_train[selected_feature], y_train, epochs=500, batch_size=16, verbose=0, callbacks=[checkpoint_callback, early_stopping_callback], validation_data=(X_test[selected_feature], y_test))\n",
    "        \n",
    "        model = tf.keras.models.load_model('./keras_models/2_3_1_best_model.keras')\n",
    "        predictions = pd.Series(model.predict(X_test[selected_feature]).flatten())\n",
    "        \n",
    "        y_test_ = pd.Series(y_scaler.inverse_transform(y_test.values.reshape(-1, 1)).flatten())\n",
    "        predictions = pd.Series(y_scaler.inverse_transform(predictions.values.reshape(-1, 1)).flatten())\n",
    "        \n",
    "        # Compute MAE\n",
    "        mae = MAE(predictions, y_test_)\n",
    "        mae_scores.append(mae)\n",
    "    \n",
    "    avg_mae = np.mean(mae_scores)\n",
    "    std_mae = np.std(mae_scores)  # Compute standard deviation\n",
    "    \n",
    "    print(\"###############################################\")\n",
    "    print(\"MAE Scores:\", mae_scores)\n",
    "    print(f\"{type(model)} Average MAE across {n_splits} folds: {round(avg_mae, 4)} ± {round(std_mae, 4)}\")\n",
    "    \n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_keras():\n",
    "#     import tensorflow as tf\n",
    "#     from tensorflow import keras\n",
    "#     from tensorflow.keras.models import Sequential\n",
    "#     from tensorflow.keras.layers import Dense, Convolution1D\n",
    "#     from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "#     # Define the model\n",
    "#     model = Sequential([\n",
    "#         Dense(len(X_train.columns), activation='relu', input_shape=(len(X_train.columns),)),  # Input layer (10 features)\n",
    "#         #Dense(12, activation='relu'),  # Hidden layer 1\n",
    "#         #Dense(6, activation='relu'),  # Hidden layer 2\n",
    "#         Dense(1, activation='linear')  # Output layer (for binary classification)\n",
    "#     ])\n",
    "\n",
    "#     # Define ModelCheckpoint callback\n",
    "#     checkpoint_callback = ModelCheckpoint(\n",
    "#         './keras_models/2_3_1_best_model.h5', \n",
    "#         monitor='val_mae',  # Monitor validation loss\n",
    "#         save_best_only=True,  # Save only when validation loss improves\n",
    "#         mode='auto',  # We want to minimize validation loss\n",
    "#         #verbose=1\n",
    "#     )\n",
    "\n",
    "#     # Compile the model\n",
    "#     model.compile(optimizer='adam', loss=tf.keras.losses.MeanAbsoluteError(), metrics=['mae'])\n",
    "#     model.fit(X_train, y_train, epochs=500, batch_size=16, verbose=0, callbacks=[checkpoint_callback], validation_data=(X_test, y_test))\n",
    "    \n",
    "#     model = tf.keras.models.load_model('./keras_models/2_3_1_best_model.h5')\n",
    "#     predictions = pd.Series(model.predict(X_test).flatten())\n",
    "\n",
    "\n",
    "#     y_test_ = pd.Series(y_scaler.inverse_transform(y_test.values.reshape(-1, 1)).flatten())\n",
    "#     predictions = pd.Series(y_scaler.inverse_transform(predictions.values.reshape(-1, 1)).flatten())\n",
    "\n",
    "\n",
    "#     # Compute MAE\n",
    "#     mae = MAE(predictions, y_test_)\n",
    "\n",
    "#     print(f\"{type(model)} Mean Absolute Error (MAE):\", round(mae))\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgbm_model(n_splits=10):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    mae_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        train_data = lgb.Dataset(X_train[selected_feature], label=y_train)\n",
    "        test_data = lgb.Dataset(X_test[selected_feature], label=y_test, reference=train_data)\n",
    "        \n",
    "        params = {\n",
    "            'objective': 'regression',\n",
    "            'metric': 'mae',\n",
    "            'verbose': -1\n",
    "        }\n",
    "        \n",
    "        num_round = 100\n",
    "        model = lgb.train(params, train_data, num_round, valid_sets=[test_data])\n",
    "        \n",
    "        predictions = pd.Series(model.predict(X_test[selected_feature], num_iteration=model.best_iteration))\n",
    "        \n",
    "        y_test_ = pd.Series(y_scaler.inverse_transform(y_test.values.reshape(-1, 1)).flatten())\n",
    "        predictions = pd.Series(y_scaler.inverse_transform(predictions.values.reshape(-1, 1)).flatten())\n",
    "        \n",
    "        mae = MAE(predictions, y_test_)\n",
    "        mae_scores.append(mae)\n",
    "    \n",
    "    avg_mae = np.mean(mae_scores)\n",
    "    std_mae = np.std(mae_scores)  # Compute standard deviation\n",
    "    \n",
    "    print(\"###############################################\")\n",
    "    print(\"MAE Scores:\", mae_scores)\n",
    "    print(f\"{type(model)} Average MAE across {n_splits} folds: {round(avg_mae, 4)} ± {round(std_mae, 4)}\")\n",
    "    \n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def train_lgbm_model():\n",
    "#     train_data = lgb.Dataset(X_train[selected_feature], label=y_train)\n",
    "#     test_data = lgb.Dataset(X_test[selected_feature], label=y_test, reference=train_data)\n",
    "\n",
    "\n",
    "\n",
    "#     # Define parameters for the LightGBM model\n",
    "#     params = {\n",
    "#         'objective': 'regression',  # Set the objective as regression\n",
    "#         'metric': 'mae',            # Use mean absolute error as the evaluation metric\n",
    "#         'verbose': 1                # Disable verbose output\n",
    "#     }\n",
    "\n",
    "#     # Train the LightGBM model\n",
    "#     num_round = 100\n",
    "#     model = lgb.train(params, train_data, num_round)\n",
    "\n",
    "#     # Make predictions on the test set\n",
    "#     predictions = pd.Series(model.predict(X_test[selected_feature], num_iteration=model.best_iteration))\n",
    "    \n",
    "\n",
    "#     y_test_ = pd.Series(y_scaler.inverse_transform(y_test.values.reshape(-1, 1)).flatten())\n",
    "#     predictions = pd.Series(y_scaler.inverse_transform(predictions.values.reshape(-1, 1)).flatten())\n",
    "\n",
    "#     # Compute MAE\n",
    "#     mae = MAE(predictions, y_test_)\n",
    "\n",
    "#     print(f\"{type(model)} Mean Absolute Error (MAE):\", round(mae))\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############################################\n",
      "MAE Scores: [104.375, 105.15625, 155.15625, 121.5625, 106.40625, 93.4375, 51.71875, 85.3125, 75.46875, 109.84375]\n",
      "<class 'sklearn.dummy.DummyRegressor'> Average MAE across 10 folds: 100.8438 ± 26.2209\n",
      "###############################################\n",
      "MAE Scores: [107.19115125514385, 104.33856624719758, 150.03663807997742, 151.11812912430082, 119.19817438657964, 94.51902199361629, 81.09641564090123, 117.12305851830476, 122.45232952894881, 122.77818204254035]\n",
      "<class 'lightgbm.basic.Booster'> Average MAE across 10 folds: 116.9852 ± 20.9151\n",
      "###############################################\n",
      "MAE Scores: [108.3770751953125, 114.6044921875, 157.2705078125, 156.083984375, 118.8409423828125, 99.375, 84.04541015625, 113.1817626953125, 116.26861572265625, 124.490966796875]\n",
      "<class 'sklearn.linear_model._base.LinearRegression'> Average MAE across 10 folds: 119.2539 ± 21.5635\n",
      "###############################################\n",
      "MAE Scores: [153.75, 120.15625, 162.5, 167.34375, 158.4375, 84.0625, 72.5, 190.0, 215.15625, 124.375]\n",
      "<class 'sklearn.tree._classes.DecisionTreeRegressor'> Average MAE across 10 folds: 144.8281 ± 42.4517\n",
      "###############################################\n",
      "MAE Scores: [102.89619065704306, 108.4583863216551, 154.61086403097536, 157.96583490832313, 122.74046904121893, 100.34151709855266, 79.94806538910967, 110.35553449917245, 116.5271961770651, 123.3926391123523]\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPRegressor'> Average MAE across 10 folds: 117.7237 ± 22.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "###############################################\n",
      "MAE Scores: [95.06317062024027, 96.6105987727642, 142.79330112040043, 118.35079504549503, 111.0671778023243, 89.35367432236671, 50.343459598720074, 89.78273078799248, 78.00881791114807, 108.90124087780714]\n",
      "<class 'keras.src.models.sequential.Sequential'> Average MAE across 10 folds: 98.0275 ± 23.524\n",
      "###############################################\n",
      "MAE Scores: [108.81165978580005, 109.8392276011684, 159.01225999672153, 158.37731826205746, 117.70599686278429, 100.1547789841133, 84.42804978684845, 110.06551489097146, 116.73168579873328, 122.92995649669697]\n",
      "<class 'sklearn.linear_model._ridge.Ridge'> Average MAE across 10 folds: 118.8056 ± 22.3413\n",
      "###############################################\n",
      "MAE Scores: [118.50260416666667, 144.55729166666669, 182.861328125, 160.78125, 130.59895833333334, 124.61805555555556, 99.990234375, 112.53472222222223, 125.771484375, 132.48046875]\n",
      "<class 'sklearn.linear_model._coordinate_descent.Lasso'> Average MAE across 10 folds: 133.2696 ± 22.8866\n",
      "###############################################\n",
      "MAE Scores: [118.50260416666667, 144.55729166666669, 182.861328125, 160.78125, 130.59895833333334, 124.61805555555556, 99.990234375, 112.53472222222223, 125.771484375, 132.48046875]\n",
      "<class 'sklearn.linear_model._coordinate_descent.ElasticNet'> Average MAE across 10 folds: 133.2696 ± 22.8866\n",
      "###############################################\n",
      "MAE Scores: [125.62195312500002, 104.41718750000003, 147.20286458333328, 154.79276041666668, 144.72812500000003, 91.52489583333335, 79.30078125000003, 152.4600260416667, 154.6489322916667, 118.71658854166668]\n",
      "<class 'sklearn.ensemble._forest.RandomForestRegressor'> Average MAE across 10 folds: 127.3414 ± 26.4964\n",
      "###############################################\n",
      "MAE Scores: [110.00600250025701, 116.52573075597083, 163.37481360739278, 158.07637563990022, 119.58486720711264, 104.31368180376576, 86.4399548629491, 109.87348910620263, 116.96037824943089, 123.97383792664229]\n",
      "<class 'sklearn.linear_model._bayes.BayesianRidge'> Average MAE across 10 folds: 120.9129 ± 22.2146\n",
      "###############################################\n",
      "MAE Scores: [101.05318937268035, 121.70988834829961, 158.40078596414358, 148.2272198838952, 120.895761474383, 110.24266517213078, 69.08436318155678, 101.3917498645691, 110.00129062769811, 116.7086306433734]\n",
      "<class 'sklearn.svm._classes.SVR'> Average MAE across 10 folds: 115.7716 ± 23.6643\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = { \"Baseline\": DummyRegressor(strategy=\"median\"), \n",
    "          \"LightGBM\": None, \n",
    "          \"Linear Regression\": LinearRegression(), \n",
    "          \"Decision Tree\": DecisionTreeRegressor(random_state=42), \n",
    "          \"Sklearn Neural Network\": MLPRegressor(random_state=42), \n",
    "          \"Keras Neural Network\": None, \n",
    "          \"Ridge\": Ridge(), \n",
    "          \"Lasso\": Lasso(), \n",
    "          \"Elastic\": ElasticNet(), \n",
    "          \"Random Forest\": RandomForestRegressor(), \n",
    "          \"Bayesian\": BayesianRidge(), \n",
    "          \"SVM\": SVR()}\n",
    "\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    if model_name == \"LightGBM\":\n",
    "        models[model_name] = train_lgbm_model()\n",
    "    elif model_name == \"Keras Neural Network\":\n",
    "        models[model_name] = train_keras()\n",
    "    else:\n",
    "        models[model_name] = train_model(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node sequential_62_1/dense_124_1/Relu defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\events.py\", line 84, in _run\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\alex\\AppData\\Local\\Temp\\ipykernel_18484\\893750522.py\", line 14, in <module>\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 562, in predict\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 259, in one_step_on_data_distributed\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 249, in one_step_on_data\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 104, in predict_step\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 908, in __call__\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 46, in __call__\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\models\\sequential.py\", line 213, in call\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 182, in call\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 171, in _run_through_graph\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 637, in call\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 908, in __call__\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 46, in __call__\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py\", line 148, in call\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\activations\\activations.py\", line 47, in relu\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\activations\\activations.py\", line 101, in static_call\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 15, in relu\n\nMatrix size-incompatible: In[0]: [32,15], In[1]: [9,9]\n\t [[{{node sequential_62_1/dense_124_1/Relu}}]] [Op:__inference_one_step_on_data_distributed_1384590]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[212], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m y_all \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m predictions \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(\u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mKeras Neural Network\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_all\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     16\u001b[0m y_all \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(y_scaler\u001b[38;5;241m.\u001b[39minverse_transform(y_all\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mflatten())\n\u001b[0;32m     17\u001b[0m predictions \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(y_scaler\u001b[38;5;241m.\u001b[39minverse_transform(predictions\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mflatten())\n",
      "File \u001b[1;32mc:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sequential_62_1/dense_124_1/Relu defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\events.py\", line 84, in _run\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\alex\\AppData\\Local\\Temp\\ipykernel_18484\\893750522.py\", line 14, in <module>\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 562, in predict\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 259, in one_step_on_data_distributed\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 249, in one_step_on_data\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 104, in predict_step\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 908, in __call__\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 46, in __call__\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\models\\sequential.py\", line 213, in call\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 182, in call\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 171, in _run_through_graph\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 637, in call\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 908, in __call__\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 46, in __call__\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py\", line 148, in call\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\activations\\activations.py\", line 47, in relu\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\activations\\activations.py\", line 101, in static_call\n\n  File \"c:\\Users\\alex\\Desktop\\MetaAutoML\\utils\\analysis\\ai_based_optimization\\predicting_optimal_runtime\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 15, in relu\n\nMatrix size-incompatible: In[0]: [32,15], In[1]: [9,9]\n\t [[{{node sequential_62_1/dense_124_1/Relu}}]] [Op:__inference_one_step_on_data_distributed_1384590]"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Combine train and test data for predictions\n",
    "# X_all = pd.concat([X_train[selected_feature], X_test[selected_feature]])\n",
    "# y_all = pd.concat([y_train, y_test])\n",
    "X_all = X\n",
    "y_all = y\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "predictions = pd.Series(models[\"Keras Neural Network\"].predict(X_all))\n",
    "\n",
    "y_all = pd.Series(y_scaler.inverse_transform(y_all.values.reshape(-1, 1)).flatten())\n",
    "predictions = pd.Series(y_scaler.inverse_transform(predictions.values.reshape(-1, 1)).flatten())\n",
    "\n",
    "# Create a DataFrame for results\n",
    "result_df = X_all.copy()\n",
    "result_df['runtime_limit_is'] = y_all.values\n",
    "result_df['runtime_limit_predicted'] = predictions\n",
    "\n",
    "# Assign categories manually based on the one-hot encoded columns\n",
    "def get_category(row, category_columns):\n",
    "    for col in category_columns:\n",
    "        if row[col] == 1:\n",
    "            return col.replace('category_', '')\n",
    "    return None\n",
    "\n",
    "# Find the one-hot encoded column where it's true for each row\n",
    "category_columns = [\"autogluon\", \"evalml\", \"flaml\", \"gama\", \"h2o_automl\", \"lama\", \"pycaret\", \"tpot\"]\n",
    "result_df['category'] = result_df.apply(get_category, axis=1, category_columns=category_columns)\n",
    "\n",
    "# Count the number of dots per x-axis class\n",
    "dot_counts = result_df['runtime_limit_is'].value_counts().sort_index()\n",
    "\n",
    "# Plot using Seaborn\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = sns.scatterplot(\n",
    "    y='runtime_limit_predicted',\n",
    "    x='runtime_limit_is',\n",
    "    hue='category',\n",
    "    data=result_df,\n",
    "    palette=sns.color_palette(\"hsv\", len(result_df['category'].unique()))  # Using a distinct color palette\n",
    ")\n",
    "\n",
    "# Add a custom legend for the categories\n",
    "handles, labels = scatter.get_legend_handles_labels()\n",
    "category_legend = plt.legend(handles, labels, title='Category', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.gca().add_artist(category_legend)\n",
    "\n",
    "# Create a second legend for the counts with no markers\n",
    "count_labels = [f'{int(key)}: {value}' for key, value in dot_counts.items()]\n",
    "count_legend_handles = [Line2D([0], [0], color='white', label=label) for label in count_labels]\n",
    "count_legend = plt.legend(count_legend_handles, count_labels, title='Runtime limit: Counts', bbox_to_anchor=(1.05, 0.5), loc='center left')\n",
    "\n",
    "# Add the best case line\n",
    "best_case_x = [0, 5, 10, 20, 40, 80, 160, 320, 640]\n",
    "best_case_y = [0, 5, 10, 20, 40, 80, 160, 320, 640]\n",
    "plt.plot(best_case_x, best_case_y)\n",
    "\n",
    "# Set logarithmic scales\n",
    "plt.xscale('log', base=10)\n",
    "plt.yscale('log', base=10)\n",
    "\n",
    "# Set labels and title\n",
    "plt.ylabel('Optimal runtime limit predicted')\n",
    "plt.xlabel('Optimal runtime limit measured')\n",
    "plt.title('Optimal runtime limit prediction by AutoML')\n",
    "\n",
    "# Ensure grid is enabled\n",
    "plt.grid(True)\n",
    "\n",
    "# Adjust layout to make space for legends\n",
    "plt.subplots_adjust(right=0.75)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
