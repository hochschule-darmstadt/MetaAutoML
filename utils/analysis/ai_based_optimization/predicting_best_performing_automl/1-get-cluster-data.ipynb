{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bson.objectid import ObjectId\n",
    "import os\n",
    "import collection\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name = \":balanced_accuracy\"\n",
    "\n",
    "def insert_automl_rows(df: pd.DataFrame, auto_ml_solution: str, task: str, training_id: str, dataset_name: str, dataset_size_mb: float, dataset_rows: int, dataset_cols: int, dataset_missing_values:float, \n",
    "                       dataset_duplicated_row_values:float, dataset_duplicated_col_values:float, dataset_outlier_row_values:float, runtime_limit : int, metric: float, relative_metric: float):\n",
    "    new_row = {\"AutoML_adapter\":auto_ml_solution, \"task\": task, \"trainings_id\": training_id, \"dataset_name\": dataset_name, \"dataset_size_in_mb\" : dataset_size_mb, \"dataset_rows\": dataset_rows, \"dataset_cols\": dataset_cols, \"missing_values\": dataset_missing_values, \"duplicated_rows\": dataset_duplicated_row_values, \"duplicated_cols\": dataset_duplicated_col_values, \"outliers\": dataset_outlier_row_values,\n",
    "               \"runtime_limit\": runtime_limit, metric_name: metric, \"relative_\"+ metric_name: relative_metric}\n",
    "    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_dataset_meta_informations(data):\n",
    "        dataset_size_byte = data[\"analysis\"][\"size_bytes\"]\n",
    "        dataset_size_mb = dataset_size_byte / 1000  / 1000\n",
    "        dataset_rows = data[\"analysis\"][\"number_of_rows\"]\n",
    "        dataset_cols = data[\"analysis\"][\"number_of_columns\"]\n",
    "        #compute ration of missing values\n",
    "        dataset_missing_values_total = 0\n",
    "        for k, v in data[\"analysis\"][\"missings_per_column\"].items():\n",
    "            if isinstance(v, dict):\n",
    "                for k1, v1 in v.items():\n",
    "                    if isinstance(v1, dict):\n",
    "                        for k2, v2 in v1.items():\n",
    "                            dataset_missing_values_total = dataset_missing_values_total + v2\n",
    "                    else:\n",
    "                        dataset_missing_values_total = dataset_missing_values_total + v1\n",
    "            else:\n",
    "                dataset_missing_values_total = dataset_missing_values_total + v\n",
    "        dataset_missing_values = dataset_missing_values_total\n",
    "        dataset_duplicated_row_values = len(data[\"analysis\"][\"duplicate_rows\"])\n",
    "        dataset_duplicated_col_values = len(data[\"analysis\"][\"duplicate_columns\"])\n",
    "        dataset_outlier_row_values_total = 0\n",
    "        for k, v in data[\"analysis\"][\"outlier\"].items():\n",
    "            dataset_outlier_row_values_total += len(v)\n",
    "        dataset_outlier_row_values = dataset_outlier_row_values_total\n",
    "        \n",
    "        return dataset_size_mb, dataset_missing_values, dataset_duplicated_row_values, dataset_duplicated_col_values, dataset_outlier_row_values, dataset_rows, dataset_cols\n",
    "\n",
    "def generate_best_automl_dataset(trainings: collection ,datasets: collection, models: collection,file_path: str):\n",
    "    \n",
    "    header_row = [\"AutoML_adapter\", \"task\", \"trainings_id\", \"dataset_name\", \"dataset_size_in_mb\", \"dataset_rows\", \"dataset_cols\", \"missing_values\", \"duplicated_rows\", \"duplicated_cols\", \"outliers\",\n",
    "                   \"runtime_limit\", metric_name, \"relative_\"+ metric_name]\n",
    "    df = pd.DataFrame(columns = header_row)\n",
    "    result_dict = {}\n",
    "    failed_value = 0\n",
    "    for dataset in datasets.find():\n",
    "            #Only use dataset with training series\n",
    "            if dataset[\"lifecycle_state\"] == \"active\" and dataset[\"name\"] in [\"airlines\", \"albert\", \"KDDCup09_appetency\", \"electricity\", \"bank-marketing\", \\\n",
    "                                                                        \"Amazon_employee_access\", \"riccardo\", \"eeg-eye-state\", \"jm1\", \"SpeedDating\", \\\n",
    "                                                                        \"mushroom\", \"christine\", \"phoneme\", \"Bioresponse\", \"kr-vs-kp\", \\\n",
    "                                                                        \"kc1\", \"pc4\", \"profb\", \"credit-approval\", \"breast-w\", \\\n",
    "                                                                        \n",
    "                                                                        \"covertype\", \"dionis\", \"Devnagari-Script\", \"jannis\", \"Fashion-MNIST\", \\\n",
    "                                                                        \"shuttle\", \"tamilnadu-electricity\", \"letter\", \"gas-drift\", \"har\", \\\n",
    "                                                                        \"artificial-characters\", \"optdigits\", \"waveform-5000\", \"splice\", \"car\", \\\n",
    "                                                                        \"one-hundred-plants-margin\", \"vehicle\", \"eucalyptus\", \"soybean\", \"LED-display-domain-7digit\" ]:\n",
    "                automl_dict = {}\n",
    "                #Find all trainings from the training series\n",
    "                for training in trainings.find({\"dataset_id\": str(dataset[\"_id\"])}):\n",
    "                    #Get result scores for all series\n",
    "                    task = training[\"configuration\"][\"task\"]\n",
    "                    training_id = str(training[\"_id\"])\n",
    "                    for model_id in training[\"model_ids\"]:\n",
    "                        for data in models.find({\"_id\": ObjectId(model_id)}):\n",
    "                            if data[\"lifecycle_state\"] == \"active\":\n",
    "                                if data[\"auto_ml_solution\"] in [\":autogluon\", \":evalml\", \":flaml\", \":gama\", \":lama\", \":h2o_automl\", \":pycaret\", \":tpot\"]:\n",
    "\n",
    "                                    if data[\"auto_ml_solution\"] not in automl_dict:\n",
    "                                        automl_dict[data[\"auto_ml_solution\"]] = {}\n",
    "                                    if data[\"status\"] == \"failed\":\n",
    "                                        automl_dict[data[\"auto_ml_solution\"]][training[\"configuration\"][\"runtime_limit\"]] = (failed_value, training_id)\n",
    "                                    else:\n",
    "                                        automl_dict[data[\"auto_ml_solution\"]][training[\"configuration\"][\"runtime_limit\"]] = (data[\"test_score\"][metric_name], training_id)\n",
    "                    \n",
    "                def runtimes(dict):\n",
    "                    return [key for key in [5, 10, 20, 40, 80, 160, 320, 640] if key not in dict]\n",
    "                \n",
    "\n",
    "                missing_runtime = runtimes(automl_dict[\":gama\"])\n",
    "                if len(missing_runtime) != 0:\n",
    "                    print(f\"MISSING RUNTIMES FOR DATASET {dataset['name']}, {missing_runtime}\")\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # Step 1: Initialize rankings and relative performance dictionaries\n",
    "                relative_performance = {}\n",
    "\n",
    "                # Step 2: Process each runtime\n",
    "                runtimes_dict = {}\n",
    "                for automl_name, runtime_data in automl_dict.items():\n",
    "                    for runtime, (performance, training_id) in runtime_data.items():\n",
    "                        if runtime not in runtimes_dict:\n",
    "                            runtimes_dict[runtime] = []\n",
    "                        runtimes_dict[runtime].append((automl_name, performance, training_id))\n",
    "\n",
    "                # Step 3: Calculate rankings and relative performance\n",
    "                for runtime, automl_list in runtimes_dict.items():\n",
    "                    # Sort by performance in descending order\n",
    "                    sorted_automl = sorted(automl_list, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "                    # Calculate max performance\n",
    "                    max_value = max(performance for _, performance, _ in automl_list)\n",
    "                    relative_performance[runtime] = []\n",
    "\n",
    "                    # Compute relative performance\n",
    "                    if max_value >= 0:\n",
    "                        for automl_name, performance, training_id in sorted_automl:\n",
    "                            if max_value == 0:\n",
    "                                relative_value = 0\n",
    "                            elif performance >= 0:\n",
    "                                relative_value = performance / max_value\n",
    "                            else:\n",
    "                                relative_value = None\n",
    "                            relative_performance[runtime].append((automl_name, performance, relative_value, training_id))  \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                #Meta Informations\n",
    "                dataset_size_mb, dataset_missing_values, dataset_duplicated_row_values, dataset_duplicated_col_values, dataset_outlier_row_values, dataset_rows, dataset_cols = get_dataset_meta_informations(dataset)\n",
    "                for runtime, automl_x_scores in relative_performance.items():\n",
    "                    for automl, metric, relative_metric, training_id in automl_x_scores:\n",
    "                        df = insert_automl_rows(df, automl, task, training_id, dataset['name'], dataset_size_mb, dataset_rows, dataset_cols, dataset_missing_values, dataset_duplicated_row_values, dataset_duplicated_col_values, \\\n",
    "                                                dataset_outlier_row_values, runtime, metric, relative_metric)\n",
    "                    \n",
    "                \n",
    "    if not os.path.exists(file_path):\n",
    "        os.makedirs(file_path)\n",
    "\n",
    "    df.to_csv(os.path.join(file_path,\"datasetBestAutoMLData.csv\"))\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alex\\AppData\\Local\\Temp\\ipykernel_28980\\2786889328.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script is for updating the runtime prediction parameters\n",
    "\n",
    "For calculating the new runtime prediction parameters edit the following variables or rename the collections in MongoDBCompass\n",
    "\"\"\"\n",
    "# Set here your database connection\n",
    "client = pymongo.MongoClient(\"mongodb://root:example@localhost:27017/\")\n",
    "\n",
    "# fill in the name of your database\n",
    "db = client[\"ai-optimization\"]\n",
    "\n",
    "# Collection Name\n",
    "#Ã¤ndere die Namen demenstrpchend nach den collection namen aus deiner Datenbank ab\n",
    "trainings = db[\"trainings\"]\n",
    "datasets = db[\"datasets\"]\n",
    "models = db[\"models\"]\n",
    "\n",
    "# Only edit when changing the folder structure\n",
    "file_path = \"../data\"\n",
    "\n",
    "\n",
    "#reads the information from the database and saves them in a csv file\n",
    "generate_best_automl_dataset(trainings, datasets, models, file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
