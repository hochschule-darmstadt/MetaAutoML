import os.path

import sys
import pickle
import json
from predict_time_sources import feature_preparation, SplitMethod
from autogluon.tabular import TabularDataset, TabularPredictor

import pandas as pd
import numpy as np
import re

if __name__ == '__main__':
    filepath = sys.argv[1]
    config_path = sys.argv[2]
    save_path = sys.argv[3]
    X = None

    with open(config_path) as file:
        config_json = json.load(file)

    config_json["dataset_configuration"] = json.loads(config_json["dataset_configuration"])
    targets = []
    for key in config_json["dataset_configuration"]["schema"]:
        #Get target columns list
        if config_json["dataset_configuration"]["schema"][key].get("role_selected", "") == ":target":
            targets.append(key)
    target = targets[0]

    delimiters = {
        "comma":        ",",
        "semicolon":    ";",
        "space":        " ",
        "tab":          "\t",
    }
    configuration = {
        "filepath_or_buffer": filepath,
        "delimiter": delimiters[config_json['dataset_configuration']['file_configuration']['delimiter']],
        "skiprows": (config_json['dataset_configuration']['file_configuration']['start_row']-1),
        "decimal": config_json['dataset_configuration']['file_configuration']['decimal_character'],
        "escapechar": config_json['dataset_configuration']['file_configuration']['escape_character'],
        "encoding": config_json['dataset_configuration']['file_configuration']['encoding'],
    }
    if config_json['dataset_configuration']['file_configuration']['thousands_seperator'] != "":
        configuration["thousands"] = config_json['dataset_configuration']['file_configuration']['thousands_seperator']

    X = pd.read_csv(**configuration)
    #Rename untitled columns to correct name
    for column in X:
        if re.match(r"Unnamed: [0-9]+", column):
            X.rename(columns={column: f"Column{X.columns.get_loc(column)}"}, inplace=True)

    X, y = feature_preparation(X, config_json["dataset_configuration"]["schema"].items(), config_json["dataset_configuration"]["file_configuration"]["datetime_format"], is_prediction=True)

    # load model and make predictions
    print("starting to load model")
    automl = TabularPredictor.load(os.path.join(sys.path[0], 'model_gluon.gluon'))

    predicted_y = automl.predict(X, as_pandas=False)
    predicted_y = np.reshape(predicted_y, (-1, 1))
    pd.DataFrame(data=predicted_y, columns=["predicted"]).to_csv(save_path)
