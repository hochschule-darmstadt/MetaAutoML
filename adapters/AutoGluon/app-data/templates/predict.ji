import os.path

import sys
import pickle
import json
from predict_time_sources import feature_preparation, DataType, SplitMethod
from autogluon.tabular import TabularDataset, TabularPredictor

import pandas as pd
import numpy as np

if __name__ == '__main__':
    filepath = sys.argv[1]
    config_path = sys.argv[2]
    save_path = sys.argv[3]
    X = None

    with open(config_path) as file:
        config_json = json.load(file)

    config_json["dataset_configuration"] = json.loads(config_json["dataset_configuration"])
    target = config_json["configuration"]["target"]
    features = config_json["dataset_configuration"]["column_datatypes"]
    features.pop(target, None)
    features = features.items()
    delimiters = {
        "comma":        ",",
        "semicolon":    ";",
        "space":        " ",
        "tab":          "\t",
    }

    X = pd.read_csv(filepath, delimiter=delimiters[config_json["dataset_configuration"]['file_configuration']['delimiter']], escapechar=config_json["dataset_configuration"]['file_configuration']['escape_character'], decimal=config_json["dataset_configuration"]['file_configuration']['decimal_character']).drop(target, axis=1, errors='ignore')
    # split training set
    X = X.iloc[:]

    X = feature_preparation(X, features)

    # load model and make predictions
    print("starting to load model")
    automl = TabularPredictor.load(os.path.join(sys.path[0], 'model_gluon.gluon'))

    predicted_y = automl.predict(X, as_pandas=False)
    predicted_y = np.reshape(predicted_y, (-1, 1))
    pd.DataFrame(data=predicted_y, columns=["predicted"]).to_csv(save_path)
