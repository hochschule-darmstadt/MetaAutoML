{
    // Verwendet IntelliSense zum Ermitteln möglicher Attribute.
    // Zeigen Sie auf vorhandene Attribute, um die zugehörigen Beschreibungen anzuzeigen.
    // Weitere Informationen finden Sie unter https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "WIN LAMA Adapter",
            "type": "python",
            "request": "launch",
            "program": "LAMAServer.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "env": {
                "PYTHONPATH": ".;dependency-injection;AutoMLs;Utils;../Utils/Utils;../Utils/AutoMLs;../GRPC/Adapter;",
                "GRPC_SERVER_PORT": "60066",
                "PYTHON_ENV": ".venv/Scripts/python",
                "USE_DEV_CONFIG": "YES",
                "EXPLAINER_DASHBOARD_PORT_START": "5700",
                "EXPLAINER_DASHBOARD_PORT_END": "5799",
                "ADAPTER_NAME": "lama",
                "JOB_FILE_NAME": "lama-job.json",
                "GRPC_SERVER_ADDRESS": "127.0.0.1",
                "EXPORT_ZIP_FILE_NAME": "lama-export",
                "TRAINING_PATH": "app-data/training",
                "JOB_FOLDER_NAME": "job",
                "MODEL_FOLDER_NAME": "model",
                "EXPORT_FOLDER_NAME": "export",
                "RESULT_FOLDER_NAME": "result",
                "TEMPLATES_PATH": "app-data/templates",
                "LOCAL_EXECUTION": "YES",
                "RUNNING_IN_WSL": "NO",
                "DASHBOARD_FOLDER_NAME": "dashboard",
                "WSL_METAAUTOML_PATH": "/mnt/c/Users/alex/Desktop/MetaAutoML",
                "ONTOLOGY_PATH": "../../controller/managers/ontology/ML_Ontology.ttl"
            },
        },
        {
            "name": "UNIX LAMA Adapter",
            "type": "python",
            "request": "launch",
            "program": "LAMAServer.py",
            "console": "integratedTerminal",
            "justMyCode": true,
            "env": {
                "PYTHONPATH": ".:dependency-injection:AutoMLs:Utils:../Utils/Utils:../Utils/AutoMLs:../GRPC/Adapter:",
                "GRPC_SERVER_PORT": "50065",
                "PYTHON_ENV": ".venv/bin/python",
                "USE_DEV_CONFIG": "YES",
                "EXPLAINER_DASHBOARD_PORT_START": "5700",
                "EXPLAINER_DASHBOARD_PORT_END": "5799",
                "ADAPTER_NAME": "lama",
                "JOB_FILE_NAME": "lama-job.json",
                "GRPC_SERVER_ADDRESS": "127.0.0.1",
                "EXPORT_ZIP_FILE_NAME": "lama-export",
                "TRAINING_PATH": "app-data/training",
                "JOB_FOLDER_NAME": "job",
                "MODEL_FOLDER_NAME": "model",
                "EXPORT_FOLDER_NAME": "export",
                "RESULT_FOLDER_NAME": "result",
                "TEMPLATES_PATH": "app-data/templates",
                "LOCAL_EXECUTION": "YES",
                "RUNNING_IN_WSL": "NO",
                "DASHBOARD_FOLDER_NAME": "dashboard",
                "WSL_METAAUTOML_PATH": "/mnt/c/Users/alex/Desktop/MetaAutoML",
                "ONTOLOGY_PATH": "../../controller/managers/ontology/ML_Ontology.ttl"
            },
        },
        {
            "name": "WIN LAMA Adapter Test",
            "type": "python",
            "request": "launch",
            "purpose": ["debug-test"],
            "program": "tests/test_tabular_task.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "env": {
                "PYTHONPATH": ".;dependency-injection;AutoMLs;Utils;../Utils/Utils;../Utils/AutoMLs;../GRPC/Adapter;",
                "GRPC_SERVER_PORT": "50062",
                "PYTHON_ENV": ".venv/Scripts/python",
                "USE_DEV_CONFIG": "YES",
                "PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION": "python"
            },
        },
    ]
}
