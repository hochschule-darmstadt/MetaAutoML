version: "3.3"
services:
  # sometimes when building the controller it does not copy the contents of the datasets folder.
  # This is probably a caching docker caching issue, which can be fixed with:
  # 'make clean-hard'
  controller:
    build:
      context: ./
      dockerfile: ./controller/Dockerfile
    container_name: controller
    depends_on:
      - mongo
    # we map the port of the controller to the host.
    # This way we can either connect locally with localhost:5001
    # or from a docker container that accesses host.docker.internal:5001
    ports:
      - "5001:5001"
    environment:
      # The environment variables are set manually here in docker-compose.
      # But in kubernetes the environment variables are set as <SERVICE_NAME>_SERVICE_HOST and <SERVICE_NAME>_SERVICE_PORT
      # Therefore the services must be named accordingly in the kubernetes files.
      - AUTOKERAS_SERVICE_HOST=autokeras
      - AUTOKERAS_SERVICE_PORT=50052
      - MLJAR_SERVICE_HOST=mljar
      - MLJAR_SERVICE_PORT=50053
      - MCFLY_SERVICE_HOST=mcfly
      - MCFLY_SERVICE_PORT=50054
      - SKLEARN_SERVICE_HOST=sklearn
      - SKLEARN_SERVICE_PORT=50055
      - FLAML_SERVICE_HOST=flaml
      - FLAML_SERVICE_PORT=50056
      - AUTOGLUON_SERVICE_HOST=gluon
      - AUTOGLUON_SERVICE_PORT=50057
      #- AUTOCVE_SERVICE_HOST=autocve
      #- AUTOCVE_SERVICE_PORT=50058
      - PYTORCH_SERVICE_HOST=pytorch
      - PYTORCH_SERVICE_PORT=50059
      #- ALPHAD3M_SERVICE_HOST=alphad3m
      #- ALPHAD3M_SERVICE_PORT=50060
      - EVALML_SERVICE_HOST=evalml
      - EVALML_SERVICE_PORT=50062
      - PYCARET_SERVICE_HOST=pycaret
      - PYCARET_SERVICE_PORT=50063
      - TPOT_SERVICE_HOST=tpot
      - TPOT_SERVICE_PORT=50064
      - GAMA_SERVICE_HOST=gama
      - GAMA_SERVICE_PORT=50065
      - LAMA_SERVICE_HOST=lama
      - LAMA_SERVICE_PORT=50066
      - PERSISTENCE_LOGGING_LEVEL=DEBUG
      - SERVER_LOGGING_LEVEL=DEBUG
      - ONTOLOGY_LOGGING_LEVEL=DEBUG
      - BLACKBOARD_LOGGING_LEVEL=DEBUG
      - WIN_DEV_MACHINE=NO
      - KUBERNETES_CLUSTER=NO
    volumes:
      - datasets:/app/app-data/datasets
      - training:/app/app-data/training
      - training-autokeras:/app/app-data/training/autokeras
      - training-mljar:/app/app-data/training/mljar
      - training-sklearn:/app/app-data/training/sklearn
      - training-flaml:/app/app-data/training/flaml
      - training-gluon:/app/app-data/training/gluon
      #- training-autocve:/app/app-data/training/autocve
      - training-pytorch:/app/app-data/training/pytorch
      #- training-alphad3m:/app/app-data/training/alphad3m
      - training-mcfly:/app/app-data/training/mcfly
      - training-evalml:/app/app-data/training/evalml
      - training-pycaret:/app/app-data/training/pycaret
      - training-tpot:/app/app-data/training/tpot
      - training-gama:/app/app-data/training/gama
      - training-lama:/app/app-data/training/lama

  mongo:
    image: mongo
    container_name: mongo
    ports:
      - "27017:27017"

    # limit log verbosity
    command: --quiet --logpath /dev/null

    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: example
    volumes:
      - mongodata:/data/configdb
      - mongodata:/data/db

#     adapters do not need to be available from the host machine -> no port mappings

  autokeras:
    build:
      context: ./adapters
      dockerfile: ./AutoKeras/Dockerfile
    container_name: autokeras
    depends_on:
      - mljar
    environment:
      - GRPC_SERVER_PORT=50052
      - EXPLAINER_DASHBOARD_PORT_START=6000
      - EXPLAINER_DASHBOARD_PORT_END=6009
      - DOCKER_COMPOSE"=YES
    volumes:
      - datasets:/app/app-data/datasets
      - training-autokeras:/app/app-data/training
    ports:
      - "6000-6009:6000-6009"

  mljar:
    build:
      context: ./adapters
      dockerfile: ./MLJAR/Dockerfile
    container_name: mljar
    depends_on:
      - flaml
    environment:
      - GRPC_SERVER_PORT=50053
      - EXPLAINER_DASHBOARD_PORT_START=6010
      - EXPLAINER_DASHBOARD_PORT_END=6019
      - DOCKER_COMPOSE"=YES
    volumes:
      - datasets:/app/app-data/datasets
      - training-mljar:/app/app-data/training
    ports:
      - "6010-6019:6010-6019"

#   mcfly:
#     build:
#       context: ./adapters
#       dockerfile: ./Mcfly/Dockerfile
#     container_name: mcfly
#     environment:
#       - GRPC_SERVER_PORT=50054
#     volumes:
#       - datasets:/app/app-data/datasets
#       - training-mcfly:/app/app-data/training

#   sklearn:
#     build:
#       context: ./adapters
#       dockerfile: ./AutoSklearn/Dockerfile
#     container_name: sklearn
#     environment:
#       - GRPC_SERVER_PORT=50055
#       - EXPLAINER_DASHBOARD_PORT_START=6020
#       - EXPLAINER_DASHBOARD_PORT_END=6029
#     volumes:
#       - datasets:/app/app-data/datasets
#       - training-sklearn:/app/app-data/training
#     ports:
#       - "6020-6029:6020-6029"

  flaml:
    build:
      context: ./adapters
      dockerfile: ./FLAML/Dockerfile
    container_name: flaml
    depends_on:
      - gluon
    environment:
      - GRPC_SERVER_PORT=50056
      - EXPLAINER_DASHBOARD_PORT_START=6030
      - EXPLAINER_DASHBOARD_PORT_END=6039
      - DOCKER_COMPOSE"=YES
    volumes:
      - datasets:/app/app-data/datasets
      - training-flaml:/app/app-data/training
    ports:
      - "6030-6039:6030-6039"

  gluon:
    build:
      context: ./adapters
      dockerfile: ./AutoGluon/Dockerfile
    container_name: gluon
    depends_on:
      - evalml
    environment:
      - GRPC_SERVER_PORT=50057
      - EXPLAINER_DASHBOARD_PORT_START=6040
      - EXPLAINER_DASHBOARD_PORT_END=6049
      - DOCKER_COMPOSE"=YES
    volumes:
      - datasets:/app/app-data/datasets
      - training-gluon:/app/app-data/training
    ports:
      - "6040-6049:6040-6049"

#   #autocve:
#   #  build:
#   #    context: ./adapters
#   #    dockerfile: ./AutoCVE/Dockerfile
#   #  container_name: autocve
#   #  environment:
#   #    - GRPC_SERVER_PORT=50058
#   #  volumes:
#   #    - datasets:/app/app-data/datasets
#   #    - training-autocve:/app/app-data/training

#   pytorch:
#     build:
#       context: ./adapters
#       dockerfile: ./AutoPytorch/Dockerfile
#     container_name: pytorch
#     environment:
#       - GRPC_SERVER_PORT=50059
#       - EXPLAINER_DASHBOARD_PORT_START=6050
#       - EXPLAINER_DASHBOARD_PORT_END=6059
#     volumes:
#       - datasets:/app/app-data/datasets
#       - training-pytorch:/app/app-data/training
#     ports:
#       - "6050-6059:6050-6059"

#   #alphad3m:
#   #  build:
#   #    context: ./adapters
#   #    dockerfile: ./AlphaD3M/Dockerfile
#   #  container_name: alphad3m
#   #  environment:
#   #    - GRPC_SERVER_PORT=50060
#   #  volumes:
#   #    - datasets:/app/app-data/datasets
#   #    - training-alphad3m:/app/app-data/training


  evalml:
    build:
      context: ./adapters
      dockerfile: ./EvalML/Dockerfile
    container_name: evalml
    depends_on:
      - pycaret
    environment:
      - GRPC_SERVER_PORT=50062
      - EXPLAINER_DASHBOARD_PORT_START=6060
      - EXPLAINER_DASHBOARD_PORT_END=6069
      - DOCKER_COMPOSE"=YES
    volumes:
      - datasets:/app/app-data/datasets
      - training-evalml:/app/app-data/training
    ports:
      - "6060-6069:6060-6069"

  pycaret:
    build:
      context: ./adapters
      dockerfile: ./PyCaret/Dockerfile
    container_name: pycaret
    depends_on:
      - tpot
    environment:
      - GRPC_SERVER_PORT=50063
      - EXPLAINER_DASHBOARD_PORT_START=6070
      - EXPLAINER_DASHBOARD_PORT_END=6079
      - DOCKER_COMPOSE"=YES
    volumes:
      - datasets:/app/app-data/datasets
      - training-pycaret:/app/app-data/training
    ports:
      - "6070-6079:6070-6079"

  tpot:
    build:
      context: ./adapters
      dockerfile: ./TPOT/Dockerfile
    container_name: tpot
    depends_on:
      - gama
    environment:
      - GRPC_SERVER_PORT=50064
      - EXPLAINER_DASHBOARD_PORT_START=6080
      - EXPLAINER_DASHBOARD_PORT_END=6089
      - DOCKER_COMPOSE"=YES
    volumes:
      - datasets:/app/app-data/datasets
      - training-tpot:/app/app-data/training
    ports:
      - "6080-6089:6080-6089"

  gama:
    build:
      context: ./adapters
      dockerfile: ./GAMA/Dockerfile
    container_name: gama
    depends_on:
      - lama
    environment:
      - GRPC_SERVER_PORT=50065
      - EXPLAINER_DASHBOARD_PORT_START=6090
      - EXPLAINER_DASHBOARD_PORT_END=6099
      - DOCKER_COMPOSE"=YES
    volumes:
      - datasets:/app/app-data/datasets
      - training-gama:/app/app-data/training
    ports:
      - "6090-6099:6090-6099"

  lama:
    build:
      context: ./adapters
      dockerfile: ./LAMA/Dockerfile
    container_name: lama
    environment:
      - GRPC_SERVER_PORT=50066
      - EXPLAINER_DASHBOARD_PORT_START=6100
      - EXPLAINER_DASHBOARD_PORT_END=6109
      - DOCKER_COMPOSE"=YES
    volumes:
      - datasets:/app/app-data/datasets
      - training-lama:/app/app-data/training
    ports:
      - "6100-6109:6100-6109"

volumes:
  datasets: # shared volume between controller, adapters and frontend/dummy to transfer datasets
   # shared volumes between controller and adapters to transfer training files e.g. *.zip file
  training-autokeras:
  training-sklearn:
  training-flaml:
  training-gluon:
  training-pytorch:
  #training-autocve:
  training-mljar:
  #training-alphad3m:
  training-mcfly:
  training-evalml:
  training-pycaret:
  training-tpot:
  training-gama:
  training-lama:

  # shared volume between controller and frontend / dummy to transfer training
  training:
  mongodata:
