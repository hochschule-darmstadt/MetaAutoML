# MetaAutoML

## How to check out the latest version

Clone MetaAutoML Repository:  
`git clone git@github.com:hochschule-darmstadt/MetaAutoML.git`

## Quick Start Guide

Please refer to the [docker run guide]([https://github.com/hochschule-darmstadt/MetaAutoML/wiki/III-Docker-run-guide](https://github.com/hochschule-darmstadt/MetaAutoML/wiki/1.-Docker-run-guide)) in the wiki.

## Docker Setup

There is one main docker-compose file, which configures all backend modules to run in a local setup. Backend modules
being the Controller and all Adapters. Then there are two supplementary docker-compose files
namely `docker-compose-frontend.yml` and `docker-compose-dummy.yml` which can be used to start the dummy or the frontend
also in a separate docker-container to go along with the backend.  
It is recommended to use the Makefile to quickly start the desired setup. So examine the Makefile and start whatever
setup you want.

Once you have the backend running you can connect to it on the host machine on port `5001`, because that port is mapped
from the host into the container which the Controller runs in. All Adapters are not mapped to the host but communicate
with the Controller inside the internal docker-compose network.  
So when running the backend in docker-compose you can connect to it from the frontend or dummy running locally.  
However, as explained there is also the option to run the frontend or dummy in docker-compose directly. The
docker-compose setup for dummy and frontend then arranges that they connect to the controller over the mapped port 5001.
This way the backend setup is ready to work with either the local or the containerized frontend/dummy interface.

The recommended option for local tests is the following:  
`make compose-up-rebuild-backend`  
because it runs all backend modules in the foreground with nice colouring for their outputs to stdout. Then you cann
connect with a local dummy to the setup.

### Figuring out what in the containers happens

You can run the following command to open a shell session inside a container:  
`docker exec -it <container-name> bash`  
As the adapters and the controller share volumes you can access the adapters output when openinng a shell session inside the `controller` with `docker exec -it controller bash` and navigating to /app/app-data/output.  
Job files are the only files that are generated by the adapter which are not visible from the controller, because they are not important for the controller and therefore are not located inside a shared volume.
